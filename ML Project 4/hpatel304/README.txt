Name: Harsh Patel
Course: CS4641
Assignment: Reinforcement Learning

I utilized the RL_Sim software (by Rohit Kelkar and Vivek Mehta from Carnegie Mellon University) to run Value Iteration, Policy Iteration, and Q-Learning on two pre-loaded gridworld mazes (multipleGoal1.maze and big.maze). You can also find the RL_Sim software here: https://www.cs.cmu.edu/~awm/rlsim/

In order to run my MDPs to verify my results, follow the steps outlined below:
1. Launch RL_Sim using the command line / terminal and the following command: java -jar rl_sim.jar
2. Select the appropriate algorithm (either Value Iteration, Policy Iteration, or Q-Learning)
3. Load the appropriate maze (either multipleGoals1.maze or big.maze)
4. Set the hyperparameters to the desired values
5. Initialize
6. Execute (for Value Iteration and Policy Iteration) or Cycles (for Q-Learning)

Files included in this zip:
RL_Sim (directory with RL_Sim jar file and all files required to run experiments,
README.txt,
hpatel304-analysis.pdf,
Raw_Data.xlsx,
